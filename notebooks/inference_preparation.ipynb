{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import numpy as np\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import AllChem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read SDF file and extract features\n",
    "def read_sdf_file(file_path):\n",
    "    suppl = Chem.SDMolSupplier(file_path)\n",
    "    smiles_list = []\n",
    "    for mol in suppl:\n",
    "        if mol is not None:\n",
    "            # Extract SMILES structure\n",
    "            smiles = Chem.MolToSmiles(mol)\n",
    "            smiles_list.append(smiles)\n",
    "    return np.array(smiles_list) \n",
    "\n",
    "# Function to create DataLoader\n",
    "def create_dataloader(data, batch_size=32):\n",
    "    tensor_data = torch.tensor(data, dtype=torch.float32)\n",
    "    dataset = TensorDataset(tensor_data)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=True)\n",
    "    return dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[09:57:16] Warning: conflicting stereochemistry at atom 5 ignored. by rule 1a.\n",
      "[09:57:16] Warning: conflicting stereochemistry at atom 5 ignored. by rule 1a.\n",
      "[09:57:16] Warning: conflicting stereochemistry at atom 16 ignored. by rule 1a.\n",
      "[09:57:16] Warning: conflicting stereochemistry at atom 16 ignored. by rule 1a.\n",
      "[09:57:53] Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "[09:57:53] ERROR: Could not sanitize molecule ending on line 34094083\n",
      "[09:57:53] ERROR: Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "[09:58:05] Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "[09:58:05] ERROR: Could not sanitize molecule ending on line 37735146\n",
      "[09:58:05] ERROR: Explicit valence for atom # 2 B, 5, is greater than permitted\n",
      "[09:58:05] Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "[09:58:05] ERROR: Could not sanitize molecule ending on line 37844463\n",
      "[09:58:05] ERROR: Explicit valence for atom # 1 B, 5, is greater than permitted\n",
      "[09:59:29] Explicit valence for atom # 0 C, 6, is greater than permitted\n",
      "[09:59:29] ERROR: Could not sanitize molecule ending on line 64433972\n",
      "[09:59:29] ERROR: Explicit valence for atom # 0 C, 6, is greater than permitted\n",
      "[09:59:35] Explicit valence for atom # 0 C, 6, is greater than permitted\n",
      "[09:59:35] ERROR: Could not sanitize molecule ending on line 66452007\n",
      "[09:59:35] ERROR: Explicit valence for atom # 0 C, 6, is greater than permitted\n",
      "[10:00:46] Explicit valence for atom # 0 B, 5, is greater than permitted\n",
      "[10:00:46] ERROR: Could not sanitize molecule ending on line 89092447\n",
      "[10:00:46] ERROR: Explicit valence for atom # 0 B, 5, is greater than permitted\n",
      "[10:00:47] Warning: conflicting stereochemistry at atom 5 ignored. by rule 2b.\n",
      "[10:00:47] Warning: conflicting stereochemistry at atom 7 ignored. by rule 1a.\n",
      "[10:00:47] Warning: conflicting stereochemistry at atom 7 ignored. by rule 1a.\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "sdf_file_path = '../data/screening_data/screening.sdf'\n",
    "data = read_sdf_file(sdf_file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCCOc1ccc(C(O)(CC)C(CN2CCOCC2)c2ccccc2)cc1',\n",
       "       'Cc1cccc(N2C(=O)C(Cl)=C(Nc3ccccc3O)C2=O)c1C',\n",
       "       'O=C(Cc1cccs1)Nc1cccc(-c2nc3cc4ccccc4cc3[nH]2)c1', ...,\n",
       "       'CCN1CCN(C(=O)c2cc(C(C)C)n[nH]2)CC1',\n",
       "       'O=C(c1ccccc1)N1CC(c2ncco2)C2(CCN(CC3CCCCC3)CC2)C1',\n",
       "       'Cc1ncc(C(=O)NCc2ccccc2)c(C2CCN(CCc3cccnc3)CC2)n1'], dtype='<U141')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_batches(data, batch_size):\n",
    "    for i in range(0, len(data), batch_size):\n",
    "        yield data[i:i + batch_size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUs available: 3\n",
      "GPU 0: NVIDIA A100 80GB PCIe\n",
      "GPU 1: NVIDIA A100 80GB PCIe\n",
      "GPU 2: NVIDIA A100 80GB PCIe\n",
      "Using GPU 1: NVIDIA A100 80GB PCIe\n"
     ]
    }
   ],
   "source": [
    "# Check if CUDA is available\n",
    "if torch.cuda.is_available():\n",
    "    # Get the number of GPUs available\n",
    "    num_gpus = torch.cuda.device_count()\n",
    "    print(f\"Number of GPUs available: {num_gpus}\")\n",
    "    \n",
    "    # Print the name of each GPU\n",
    "    for i in range(num_gpus):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "    \n",
    "    # Select a specific GPU (e.g., GPU 0)\n",
    "    selected_gpu = 1\n",
    "    device = torch.device(f\"cuda:{selected_gpu}\")\n",
    "    print(f\"Using GPU {selected_gpu}: {torch.cuda.get_device_name(selected_gpu)}\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "    print(\"CUDA is not available. Using CPU.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BertModel(\n",
       "  (embeddings): BertEmbeddings(\n",
       "    (word_embeddings): Embedding(30000, 768, padding_idx=0)\n",
       "    (position_embeddings): Embedding(512, 768)\n",
       "    (token_type_embeddings): Embedding(2, 768)\n",
       "    (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "  )\n",
       "  (encoder): BertEncoder(\n",
       "    (layer): ModuleList(\n",
       "      (0-11): 12 x BertLayer(\n",
       "        (attention): BertAttention(\n",
       "          (self): BertSdpaSelfAttention(\n",
       "            (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "          (output): BertSelfOutput(\n",
       "            (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "        (intermediate): BertIntermediate(\n",
       "          (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (intermediate_act_fn): GELUActivation()\n",
       "        )\n",
       "        (output): BertOutput(\n",
       "          (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          (dropout): Dropout(p=0.1, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (pooler): BertPooler(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (activation): Tanh()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import BertTokenizerFast, BertModel\n",
    "checkpoint = 'unikei/bert-base-smiles'\n",
    "tokenizer_smiles = BertTokenizerFast.from_pretrained(checkpoint)\n",
    "model_smiles = BertModel.from_pretrained(checkpoint)\n",
    "model_smiles.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_embeddings(batch, tokenizer, model,device):\n",
    "    batch_list = batch.tolist()\n",
    "    inputs = tokenizer(batch_list, return_tensors='pt', padding=True, truncation=True).to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    embeddings = outputs.last_hidden_state[:, 1:-1, :].mean(dim=1).cpu().numpy().tolist() \n",
    "    return embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pyarrow as pa\n",
    "import pyarrow.parquet as pq\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Create a Parquet writer schema\n",
    "schema = pa.schema([\n",
    "    ('ID', pa.string()),\n",
    "    ('encoding', pa.list_(pa.float64()))\n",
    "])\n",
    "\n",
    "# Universal function to write embeddings to Parquet\n",
    "def write_embeddings_to_parquet(data, batch_size, parquet_file, generate_embedding_func, tokenizer, model, device):\n",
    "    num_newlines = len(data)\n",
    "    total_batches = (num_newlines + batch_size - 1) // batch_size\n",
    "\n",
    "    writer = None\n",
    "\n",
    "    for batch in tqdm(create_batches(data, batch_size), total=total_batches, desc=\"Processing batches\"):\n",
    "        embeddings = generate_embedding_func(batch,tokenizer, model, device)\n",
    "        df = pd.DataFrame({'ID': batch, 'encoding': embeddings})\n",
    "        \n",
    "        table = pa.Table.from_pandas(df, schema=schema)\n",
    "        \n",
    "        if writer is None:\n",
    "            writer = pq.ParquetWriter(parquet_file, schema)\n",
    "        \n",
    "        writer.write_table(table)\n",
    "        \n",
    "        # Clear CUDA cache to free up memory\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    if writer:\n",
    "        writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 256\n",
    "parquet_file_smiles = '../data/screening_data/ligand_embeddings.parquet'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../data/screening_data/smiles.npy', data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['CCCOc1ccc(C(O)(CC)C(CN2CCOCC2)c2ccccc2)cc1',\n",
       "       'Cc1cccc(N2C(=O)C(Cl)=C(Nc3ccccc3O)C2=O)c1C',\n",
       "       'O=C(Cc1cccs1)Nc1cccc(-c2nc3cc4ccccc4cc3[nH]2)c1', ...,\n",
       "       'CCN1CCN(C(=O)c2cc(C(C)C)n[nH]2)CC1',\n",
       "       'O=C(c1ccccc1)N1CC(c2ncco2)C2(CCN(CC3CCCCC3)CC2)C1',\n",
       "       'Cc1ncc(C(=O)NCc2ccccc2)c(C2CCN(CCc3cccnc3)CC2)n1'], dtype='<U141')"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing batches: 100%|██████████| 4961/4961 [17:50<00:00,  4.64it/s]\n"
     ]
    }
   ],
   "source": [
    "# Write SMILES embeddings to Parquet\n",
    "write_embeddings_to_parquet(data, batch_size, parquet_file_smiles, generate_embeddings, tokenizer_smiles, model_smiles, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_parquet(\"../data/screening_data/ligand_embeddings.parquet\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>encoding</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CCCOc1ccc(C(O)(CC)C(CN2CCOCC2)c2ccccc2)cc1</td>\n",
       "      <td>[0.4631887376308441, 1.1496385335922241, -0.16...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Cc1cccc(N2C(=O)C(Cl)=C(Nc3ccccc3O)C2=O)c1C</td>\n",
       "      <td>[0.3505532741546631, 0.6738343238830566, 0.027...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>O=C(Cc1cccs1)Nc1cccc(-c2nc3cc4ccccc4cc3[nH]2)c1</td>\n",
       "      <td>[0.2411477416753769, -0.02009040117263794, -0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Cn1ncc(N2CCC(C(=O)Nc3cccc(-c4nc5ccccc5[nH]4)c3...</td>\n",
       "      <td>[0.20003139972686768, -0.06338706612586975, -0...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>CCOC(=O)c1c(N2C(=O)C=CC2=O)sc2c1CCCC2</td>\n",
       "      <td>[0.6468941569328308, 0.5003923773765564, 0.236...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269938</th>\n",
       "      <td>CCCN(C)c1ccc2ncc(=O)n(C)c2n1</td>\n",
       "      <td>[0.6567842960357666, 0.25491511821746826, -0.2...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269939</th>\n",
       "      <td>CN(C)C(=O)c1cc(N(C)C)nc2ccccc12</td>\n",
       "      <td>[0.9823178052902222, 0.6226070523262024, -0.19...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269940</th>\n",
       "      <td>CCN1CCN(C(=O)c2cc(C(C)C)n[nH]2)CC1</td>\n",
       "      <td>[0.423491895198822, 0.19044129550457, 0.111522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269941</th>\n",
       "      <td>O=C(c1ccccc1)N1CC(c2ncco2)C2(CCN(CC3CCCCC3)CC2)C1</td>\n",
       "      <td>[0.567745566368103, 0.27047884464263916, -0.18...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1269942</th>\n",
       "      <td>Cc1ncc(C(=O)NCc2ccccc2)c(C2CCN(CCc3cccnc3)CC2)n1</td>\n",
       "      <td>[0.8176042437553406, 0.11921020597219467, -0.7...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1269943 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                        ID   \n",
       "0               CCCOc1ccc(C(O)(CC)C(CN2CCOCC2)c2ccccc2)cc1  \\\n",
       "1               Cc1cccc(N2C(=O)C(Cl)=C(Nc3ccccc3O)C2=O)c1C   \n",
       "2          O=C(Cc1cccs1)Nc1cccc(-c2nc3cc4ccccc4cc3[nH]2)c1   \n",
       "3        Cn1ncc(N2CCC(C(=O)Nc3cccc(-c4nc5ccccc5[nH]4)c3...   \n",
       "4                    CCOC(=O)c1c(N2C(=O)C=CC2=O)sc2c1CCCC2   \n",
       "...                                                    ...   \n",
       "1269938                       CCCN(C)c1ccc2ncc(=O)n(C)c2n1   \n",
       "1269939                    CN(C)C(=O)c1cc(N(C)C)nc2ccccc12   \n",
       "1269940                 CCN1CCN(C(=O)c2cc(C(C)C)n[nH]2)CC1   \n",
       "1269941  O=C(c1ccccc1)N1CC(c2ncco2)C2(CCN(CC3CCCCC3)CC2)C1   \n",
       "1269942   Cc1ncc(C(=O)NCc2ccccc2)c(C2CCN(CCc3cccnc3)CC2)n1   \n",
       "\n",
       "                                                  encoding  \n",
       "0        [0.4631887376308441, 1.1496385335922241, -0.16...  \n",
       "1        [0.3505532741546631, 0.6738343238830566, 0.027...  \n",
       "2        [0.2411477416753769, -0.02009040117263794, -0....  \n",
       "3        [0.20003139972686768, -0.06338706612586975, -0...  \n",
       "4        [0.6468941569328308, 0.5003923773765564, 0.236...  \n",
       "...                                                    ...  \n",
       "1269938  [0.6567842960357666, 0.25491511821746826, -0.2...  \n",
       "1269939  [0.9823178052902222, 0.6226070523262024, -0.19...  \n",
       "1269940  [0.423491895198822, 0.19044129550457, 0.111522...  \n",
       "1269941  [0.567745566368103, 0.27047884464263916, -0.18...  \n",
       "1269942  [0.8176042437553406, 0.11921020597219467, -0.7...  \n",
       "\n",
       "[1269943 rows x 2 columns]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "320\n"
     ]
    }
   ],
   "source": [
    "# To load the data back\n",
    "loaded_data = np.load('../data/proteins/embeddings/6VKV_GAG_embeddings.npy')\n",
    "print(len(loaded_data))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chemdiv-screening-project-ubgft5hy-py3.11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
